\section{Conclusion} \label{sec:conclusions}

Our study of a year in the life of a parallel file system provided a
variety of insights into performance variation on production systems,
including both long-term trends and transient anomalies.  These insights,
and the methods that we used to derive them, have implications for
instrumentation methods, administrative expectations, and analysis
techniques. Some of the recommendations in these findings can be acted on
now by broadening the scope of instrumentation or enhancing analysis tools based on observations in this paper.
Others more fundamentally motivate the need for ``live'' analysis of
production systems so that the lessons learned here (especially those
related to dynamic, time-dependent behavior) can be more generally extracted
at any time from a running system to produce actionable feedback.

Near term future work calls for the development of additional \tokio
connectors to incorporate additional storage resources such as burst
buffers.
In the long term, we plan to develop methods to systematically classify the
similarity of different regions from one another and enable the
determination of broad classes of performance regions.
We will also use the measured data as input for simulation frameworks to
enable the design of potential new file system features or policies that may
reduce the amount of I/O performance variation seen in production. 
\endinput

\begin{enumerate}

\TODO{these lack "implications for state of the practice"; need to take these up a level.  if we were selling this process to another center, what would they need to take from this study?}

\item \textbf{Baseline performance and performance variation changes over time.}
We have shown that the baseline peak performance for a given I/O motif on a file systems can change over time as a result of factors such as system software updates and sustained workloads motivated by external factors such as end of allocation year.
\TODO{1. you can't just measure performance on day 1}

\item \textbf{The magnitude and sign of correlation between performance and other measured metrics also varies over time.} 
We demonstrated that high CPU load can correlate with favorable performance under healthy file system conditions, and it can coincide with unfavorable performance when non-I/O workloads are impacting storage servers.
\TODO{2. be careful how you interpret your metrics; training a model on one dataset might not make it apply to others}

\item \textbf{Bandwidth, IOPS, and metadata contention are often confidently correlated with I/O performance problems are occurring.}
We were able to obtain statistically significant trends about isolated performance transients by aggregating simple binary classifications based on coincident observations of worst values within regions.
That said, some jobs defied classification using our binary classification method.
This indicates that we are still missing telemetry from important components of the I/O subsystem that contribute to performance variation.
\TODO{3. metadata contention is burstier than bandwidth, but they both affect performance.  just at different time scales}

\item The methods presented here are not dependent on SMAs, and alternative approaches for both partitioning time series data and classifying the measurements within regions can be replaced with more sophisticated methods.
What we have shown is that a great deal of information about I/O performance variation can be quantified using holistic I/O analysis and simple statistical methods.
\end{enumerate}
