% As a general rule, do not put math, special symbols or citations
% in the abstract
\begin{abstract}

I/O performance is a critical part of data-intensive
scientific computing, but it is notoriously difficult to understand
and diagnose. This problem is exacerbated by the current trend towards
deeper I/O hierarchies and more complex I/O architectures. Capturing
and visualizing system-wide performance telemetry is a key step towards
solving this problem, but identifying important events and interpreting their
significance remains a labor-intensive process that depends heavily upon human
expertise.

In this work we explore how algorithmic methods can be used to ease the
burden of extracting actionable insight from long-running production
I/O instrumentation.  We demonstrate our methodology on a full year's worth
of telemetry data collected at two leading HPC
facilities.  In doing so, we answer the following questions:
%
How do we detect critical inflection points in performance?
%
How do we assess the scope and contributing factors for a given inflection point?
%
Does intuition and methodology derived from individual application
anecdotes match the reality of long-term production behavior? 
%
Can underlying trends be identified beyond the noise of day-to-day
performance variability?

Our analysis, and key case studies derived from that analysis, reveal the
presence of both short-term and long-term performance deviations.  We also
find that the ramifications of these performance deviations are not uniform 
across applications and can thus affect users in unexpected ways.

\end{abstract}
