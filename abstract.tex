% As a general rule, do not put math, special symbols or citations
% in the abstract
\begin{abstract}

% 
% - baseline I/O performance and variability are not constant over time
% 
% - administrative activities such as maintenance patches and software updates are a significant source of time-dependent, long term performance variation
%
% - holistic I/O monitoring should incorporate environmental provenance information, such as kernel, operating system, and file system versions, to aid in correlation
% 
% - financial market technical analysis techniques can be adapted to timeseries I/O performance data to attenuate noise and identify underlying trends
%
% - Significantly stronger correlations can be found by focusing analysis on algorithmically identified regions of interest in the data.
%
% - bandwidth contention from sustained workloads often accompany sustained performance losses
%
% - the nature and magnitude of how different attributes correlate with I/O performance also change over time
% 
% - attributes that correlate with transient performance problems (IOPS and metadata contention) often differ from those that correlate with long-term performance problems (bandwidth contention).
% 

I/O performance is a critical aspect of data-intensive scientific computing,
but it is notoriously difficult to understand and diagnose. This problem
is exacerbated by the current trends toward deeper I/O hierarchies,
more complex I/O architectures, and more diverse applications that must
be sustained over multi-year production life spans.

In this work we seek to advance the state of the practice in understanding
and diagnosing large-scale I/O performance issues. We present a comprehensive I/O performance data set assembled via multiple
continuous instrumentation methods across a full year of production
storage activity, at two leadership-scale computing facilities, on five file systems, connected to three machines.
%
We demonstrate techniques to identify regions of interest in
large-scale I/O performance data sets, perform focused investigation
of both long-term trends and performance anomolies, and and uncover the
contributing factors that lead to performance fluctuation.

A year in the life of a parallel file system includes many performance
fluctuations, and those fluctuations are often correlated with different
contributing factors.  Large-scale I/O performance and variability is
not constant, and instrumentation, analysis methods, and performance
models must be adapted to prevailing conditions in order to effectively
derive actionable insight from I/O instrumentation.

%
% In this work, we explore how algorithmic methods can be used to ease the
% burden of extracting actionable insight from long-running production I/O
% instrumentation.  We demonstrate our methodology on a full year's worth
% of telemetry data collected at two leading HPC facilities.  In doing so,
% we answer the following questions: How do we detect critical inflection
% points in performance?  How do we assess the scope and contributing
% factors for a given inflection point?  Does intuition and methodology
% derived from individual application anecdotes match the reality of
% long-term production behavior?  Can underlying trends be identified
% beyond the noise of day-to-day performance variability?
%
% Our analysis, and key case studies derived from that analysis, reveal the
% presence of both short-term and long-term performance deviations.  We also
% find that the ramifications of these performance deviations are not
% uniform
% across applications and can thus affect users in unexpected ways.

\end{abstract}
