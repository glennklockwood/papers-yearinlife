\section{Introduction}

I/O performance variation has been studied extensively, and a variety of conditions have been identified as contributing factors to poor I/O performance.  Most studies have focused on enumerating the sources of I/O performance loss at a single point in time, assuming that performance loss is a transient effect due to contention from other jobs.  However, recent work~\cite{Lockwood2017} has shown that performance variation can occur over periods of days as a result of systematic, longer-term conditions of a storage system.
%
Overall performance (and thus scientific productivity) can be improved for a
wide range of users if these deviations can be identified and attributed
quickly in production.

%Such systematic, long-term I/O performance variation remains much less well understood despite its relevance to scientific campaigns that may experience uneven throughput or resource consumption over the course of months or years.  In this work, we differentiate \emph{long-term performance variation} from \emph{short-term performance variation} and characterize the factors that contribute to long-term performance variation on a diverse range of large-scale production parallel storage systems.

A number of recent efforts~\cite{Lockwood2017,Vazhkudai2017guide,Agelastos2014ldms,Kunkel2014siox} have advanced the
state of the art in scalable data collection, making it possible to observe
production systems at unprecedented scales.  It remains an open problem,
however, how go best interpret this data to quickly for maximum production
impact, and what types of instrumentation have the greatest return on
investment.

We investigate this issue by studying performance data collected
from large parallel file systems at two leadership-class HPC centers
over the course of a year of production use.  In addition to passive
instrumentation, such as system monitoring and application profiling,
we also employ active probing of I/O performance to record user-percieved
performance over time.  The breadth of the data set enables investigation
multiple time scales, ranging from days to months, to identify trends in
both absolute performance and variability.  The depth of the data set
enables correlation analysis to identify subtle relationships between
performance and a variety of system-wide metrics.

\TODO{reword below paragraph to shift focus away from methodology.}
We also develop a methodology for identifying inflection points in
long-term user-perceived performance due to factors beyond their control,
such as hardware failures, software changes, capacity constraints, or
contention.  These trends are easily overlooked or misattributed given the
complexity and inherent variability of the I/O system itself, but can have a
significant long term impact on efficiency.  Once an inflection point has
been found, we investigate methods for guiding administrators to likely
contributing factors if not outright identifying definitive root causes for
anomalous performance.

%By integrating holistic I/O monitoring throughout the
%year-long experiment, we then quantitatively show
%that common sources
%of short-term variation, such as bandwidth or metadata contention,
%play less significant role in long-term performance variation.
%Given this multiscale nature of I/O performance variation, we conclude that the probabilistic effects of transient interference \emph{and} the autocorrelative effects of long-term variation are required to capture the full picture of performance variation on parallel storage systems.

The primary contributions of this paper are as follows: \TODO{fill in
contributions.  See bold findings in text plus any methods or
recommendations that we want
to call out.}
\TODO{Is simply the collection of an unprecedented year long, multi-facility
I/O performance data set a contribution too?}
\TODO{Is the method for actively probing performance a contribution too?}

%The remainder of the paper is organized as follows.  \TODO{Fill in}
