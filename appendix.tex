\appendix

\section{Artifact Description} \label{sec:appendix/artifacts}

\subsection{Abstract}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This work demonstrates the benefits of applying active I/O performance probes with holistic I/O monitoring to identify the causes of short- and long-term performance variation.
This work is based on four components which can be applied to either replicate the exact results presented in this study or reproduce this experiment on a completely new system.
To replicate the exact results, the \emph{year-long dataset} is required.
To conduct this experiment on an entirely new system though, the \emph{TOKIO Automated Benchmark Collection} is used instead to create a new input dataset.

\subsubsection{Year-long dataset}

This dataset contains all feature vectors that were generated during this study and used to create all figures and findings presented in this work.
The dataset is a CSV file containing 11,986 feature vectors, each corresponding to a single job and containing up to 220 attributes.
96 of these attributes come from application-level monitoring, 101 come from file system workload monitoring, 21 come from file system health monitoring, 6 come from resource manager monitoring, and the remainder are job-wide metadata.
The exact number of attributes defined in each
vector depends on what connectors were available on the target platform at the time the job ran.

%scratch1@edison 2230
%scratch2@edison 2486
%scratch3@edison 2503
%cscratch@cori-knl 2522
%mira-fs1@mira 2245

\subsubsection{TOKIO Automated Benchmark Collection (TOKIO-ABC)}

TOKIO-ABC is a software repository containing specific versions of the benchmarks used, scripts which encode the specific build processes used at NERSC and ALCF, and the exact input parameters used in all tests.
This repository contains all of the necessary code and inputs to generate a new dataset for a new HPC system.
For brevity, the input parameters are not reproduced here; however, the TOKIO-ABC repository will be cited here upon acceptance of this manuscript.

\subsubsection{TOKIO-ABC utilities library (tokio-abcutils)}

tokio-abcutils is a Python library upon which the analyses performed in this study were built.
It contains routines for calculating SMAs from feature vectors and performing each correlation analysis presented.
tokio-abcutils also includes the Jupyter notebooks that were used to generate all figures in this work.

\subsubsection{pytokio framework}

pytokio~\cite{Lockwood2018tokio} is an implementation of the TOKIO framework which is required by tokio-abcutils.
It is freely available on GitHub, and the instructions included in its README are sufficient to meet the requirements of tokio-abcutils.
To translate this experiment to a new system entirely, an optional ``TOKIO Data Services'' subpackage is included to simplify automated data collection.

\subsection{Description}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Check-list (artifact meta information)}

{\small
\begin{itemize}
  \item {\bf Program: } pytokio, tokio-abc, tokio-abcutils
  \item {\bf Compilation: } pytokio and tokio-abcutils require no compilation; TOKIO-ABC includes autoconf-based build scripts to aid in compilation and deployment
  \item {\bf Data set: } Feature vectors from all 11,986 benchmark runs
  \item {\bf Run-time environment: } pytokio and tokio-abcutils require Python 2.7, pandas 0.18, matplotlib 2.0, numpy 1.11, and scipy 0.17; TOKIO-ABC requires MPI-3.0 and HDF5 1.8.
  \item {\bf Run-time state: } No specific state is required a priori.
  \item {\bf Execution: } pytokio and tokio-abcutils: command-line tools and example Jupyter notebooks; TOKIO-ABC: either a continuous integration system (e.g., Jenkins) or from cron jobs.
  \item {\bf Output: } tokio-abcutils: graphical and numerical results of intermediate analyses; TOKIO-ABC: Darshan logs and job logs
  \item {\bf Experiment workflow: } TOKIO-ABC is set up to run automatically via Jenkins, cron, or a similar scheduling tool; pytokio's \texttt{summarize\_job}~\cite{Lockwood2018tokio} tool is used to generate feature vectors; Jupyter notebooks in tokio-abcutils performs statistical analyses using these feature vectors.
  \item {\bf Experiment customization: } pytokio: via additional TOKIO connector packages or new analysis tools; tokio-abcutils: by extending analysis routines and plots in Jupyter notebooks; TOKIO-ABC: via input decks
  \item {\bf Publicly available?: } Yes
\end{itemize}
}

\subsubsection{How software can be obtained (if available)}

All components of TOKIO used in this study are BSD-licensed.
pytokio is available online\footnote{https://www.github.com/nersc/pytokio}, and TOKIO-ABC and tokio-abcutils will be published upon acceptance of this paper.

\subsubsection{Hardware dependencies}

There are no specific hardware dependencies for TOKIO or TOKIO-ABC.
There may be hardware dependencies of the component-level monitoring tools with which TOKIO integrates, but such tools are not considered artifacts of this work.

\subsubsection{Software dependencies}

\paragraph{pytokio}

pytokio specifically depends on Python 2.7, and the work here additionally used pandas 0.18.1, matplotlib 2.0.0, numpy 1.11.1, and scipy 0.17.1.
For simplicity, we opted to use the software environment provided by Continuum IO's Anaconda version 4.3.14 with matplotlib explicitly upgraded to 2.0.0.

pytokio also relies on a number of component-level monitoring tools.
As described in this paper, TOKIO can integrate with any tool that provides scalar or time-resolved data types, and pytokio includes interfaces for the following data sources:

\begin{itemize}
\item Darshan 3.1.3 % \url{http://www.mcs.anl.gov/research/projects/darshan/}.
\item ggiostat
\item LMT (as provided by Neo 2.x on Cray ClusterStor) % \url{https://github.com/LLNL/lmt}
\item Lustre 2.5.1 (health monitoring via lfs and lctl)
\item Slurm 17.02.1-2 and CLE 6.0 (job topology at NERSC)
\end{itemize}

\paragraph{TOKIO-ABC} The Automated Benchmark Collection is a meta-package that contains the specific versions of each benchmark used, specific patches applied to those upstream versions, and scripts that configure and build the collection.
As such, its external dependencies are those of the benchmark applications which include:

\begin{itemize}
\item autoconf 2.69 or later
\item automake 1.13 or newer
\item an MPI 3.0-compliant implementation of MPI
\item HDF5 1.8.14
\end{itemize}

Further details on known issues and specific version incompatibilities are documented in the TOKIO-ABC package.

\subsubsection{Datasets}

To validate this work and allow the community to build upon our experimental data, we will release the entirety of the year-long dataset including

\begin{itemize}
\item All feature vectors corresponding to all 11,986 jobs run over the experimental period
\item Unmodified Darshan logs for each TOKIO-ABC job
\end{itemize}

This CSV dataset represents TOKIO-ABC results from the five test environments presented:
Edison scratch1, scratch2, scratch3; Cori scratch; and Mira mifa-fs1.
The dataset will be labeled with feature names encoded as the first CSV line.
The mapping between feature names and their descriptions are included in tokio-abcutils.

\subsection{Installation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

After unpacking the python package source distribution, installing these libraries is a matter of performing ``\texttt{{pip install -r .}}''.
Build scripts for Mira, Cori, and Edison are included in the TOKIO-ABC source distribution, and the specific configure options used for each benchmark are defined near the top of each script.
These scripts should be portable to any Blue Gene/Q and Cray Linux 6 environment, and only minor modification should be required to build TOKIO-ABC on commodity platforms.
These build scripts configure, build, and install the benchmarks within the unpacked source repository itself, and all of the utility scripts provided assume this self-contained installation directory structure.

\subsection{Experiment workflow}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The tokio-abcutils source repository includes a \texttt{README} file that describes the experimental workflow in detail.
To summarize,

\begin{enumerate}[leftmargin=*]

\item TOKIO-ABC is set up to run the benchmark applications (HACC, VPIC, BD-CATS, and IOR) daily.
This can be done via any automated scheduling mechanism; NERSC uses cron, while ALCF uses Jenkins.

\item The \texttt{summarize\_job}~\cite{Lockwood2018tokio} utility included with pytokio is used to generate feature vectors for each benchmark result and save them as CSV-formatted values which can be read by tokio-abcutils.

\item The tokio-abcutils repository contains the plotting routines, statistical analysis functions, and Jupyter notebooks to explore the resulting feature vectors.

\end{enumerate}

Each figure presented in this manuscript is the result of an analysis notebook that is provided in tokio-abcutils repository.
Furthermore, tokio-abcutils includes a special subpackage specific to this manuscript, \texttt{sc18paper.py}, that implements and describes the specific data filtering used here.
For example, it demonstrates that this paper discounted all jobs whose Darshan log reflected less than 1 GiB of I/O being performed; this criteria was required to invalidate results from several days where the BD-CATS binary on Edison was conflicting with an update to the default HDF5 library on that system that resulted in BD-CATS performing no actual I/O.

All components of the analyses presented here (including the feature vector dataset, pytokio, and tokio-abcutils) have been tested and confirmed to run on generic UNIX-like environments outside of NERSC and ALCF (e.g., on standard MacBooks with macOS 10.13).

\subsection{Evaluation and expected result}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The figures presented in this paper can all be regenerated or manipulated using the dataset, pytokio, and tokio-abcutils.
The Jupyter notebooks included in tokio-abcutils generate PDFs or PNG images, and most notebooks also generate numerical results which can be exported as CSVs.

Detailed documentation for each analysis, its expected inputs and outputs, and the analytical methods they apply are provided as Markdown cells in each notebook.
Special care has been taken to explain each step in each notebook's analysis process for the benefit of the authors' collaboration, but these notes will also benefit anyone interested in reproducing the results presented in this work.

\subsection{Experiment customization}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Customization can be done by either adding new TOKIO connectors to interface with different component-level monitoring tools or creating new analysis tools which operate on the year-long dataset.
As an example of the former, contributing a connector that can access traffic counters to burst buffer file systems (such as collectd for DataWarp~\cite{Lockwood2018tokio}) would allow pytokio, and by extension this work, to provide more insight into how various factors may contribute to burst buffer performance in contrast to disk-based parallel file systems.
An example of the latter would be modifying the analysis notebooks to generate plots for the combinations of systems and analysis that were \emph{not} presented in this manuscript due to space constraints.

The input parameters for each performance probe benchmark are defined in \texttt{.params} files in the \texttt{inputs} subdirectory of the TOKIO-ABC repository.
These files are simple text files which specify the desired parallelism, working set size, and read/write behavior for an individual job on each line.
Application-specific documentation is provided in the repository; the most common customization is to alter the data volume and parallelism to suitably stress the underlying file system without using an excessive amount of core hours.

\subsection{Notes}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Significantly more documentation on pytokio, tokio-abcutils, TOKIO-ABC, and the year-long dataset used in this study are contained within each repository.
For additional clarity, many of the tools used to generate the figures for this manuscript are also included as self-documented Jupyter notebooks.
Finally, both pytokio and tokio-abcutils follow the Google Python Style Guide\footnote{https://google.github.io/styleguide/pyguide.html}.
In combination with Sphinx Autodoc\footnote{http://www.sphinx-doc.org/en/stable/ext/autodoc.html}, pytokio and tokio-abcutils include extensive self-documentation of their APIs which can be rendered as PDF- or HTML-formatted manuals.